# -*- coding: utf-8 -*-
"""MLKEREN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eGvdJR7GEZRImrU70kqJH5Ij1NMth8dO
"""

# Import library
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, r2_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE

data = pd.read_excel('/content/Infrastruktur Dasar IKK.xlsx')
data.head()

# Mengetahui apakah ada data yang kosong
print(data.isnull().sum())

# Mengetahui Kolomnya

print(data1.columns)

# Membuat kolom kategori
def kategori_ikk(Value):
    if Value < 100:
        return 'Rendah'
    else:
        return 'Tinggi'

data['Kategori_ikk'] = data['Value'].apply(kategori_ikk)
print(data)

# Membuat kolom baru (menggunakan nama dataframe yang benar: dataku)
data['kategori_ikk'] = data['Value'].apply(kategori_ikk)
print(data)

# Encode kategori menjadi angka
le = LabelEncoder()
data['KategoriikkEncoded'] = le.fit_transform(data['Kategori_ikk'])

# Pilih fitur dan label
X = data[['Value', 'Median Nilai Konstruksi yang Diselesaikan (rupiah)']]
y = data['KategoriikkEncoded']

# Membagi data menjadi data latih dan data uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Melatih model Random Forest
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Prediksi dan evaluasi
y_pred = model.predict(X_test)

# Evaluasi model
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Rekayasa Fitur (Contoh: Standardisasi)
scaler = StandardScaler()
X = data[['Value', 'Median Nilai Konstruksi yang Diselesaikan (rupiah)']]
X = scaler.fit_transform(X)

# Tuning Hyperparameter Model (Contoh: Grid Search)
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10],
}
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)
grid_search.fit(X_train, y_train)
model = grid_search.best_estimator_

# Menangani Ketidakseimbangan Kelas (Contoh: SMOTE)
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
model.fit(X_train_resampled, y_train_resampled)

# Evaluasi dengan Metrik yang Tepat
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns

# Dataset
data1 = {
    'Provinsi': ['PAPUA', 'PAPUA BARAT', 'DKI JAKARTA', 'KEPULAUAN RIAU', 'KALIMANTAN TIMUR', 'MALUKU UTARA',
                 'KALIMANTAN BARAT', 'MALUKU', 'JAWA BARAT', 'KALIMANTAN TENGAH', 'BALI', 'SULAWESI UTARA',
                 'KALIMANTAN UTARA', 'NUSA TENGGARA BARAT', 'SUMATERA UTARA', 'KEPULAUAN BANGKA BELITUNG',
                 'DI YOGYAKARTA', 'KALIMANTAN SELATAN', 'JAWA TENGAH', 'ACEH', 'JAWA TIMUR', 'RIAU', 'SULAWESI TENGGARA',
                 'BANTEN', 'SUMATERA BARAT', 'JAMBI', 'BENGKULU', 'GORONTALO', 'SULAWESI SELATAN', 'NUSA TENGGARA TIMUR',
                 'SULAWESI TENGAH', 'SUMATERA SELATAN', 'LAMPUNG', 'SULAWESI BARAT'],
    'Value': [192.570007324219, 124.819999694824, 121.480003356934, 115.970001220703, 115.650001525879,
              110.599998474121, 109.370002746582, 107.970001220703, 105.970001220703,104.769996643066,
              104.73999786377, 104.73999786377, 104.690002441406, 104.440002441406, 103.400001525879,
              102.779998779297, 102.370002746582, 102.26000213623, 100.629997253418, 100.589996337891,
              100.019996643066, 99.2099990844727, 98.0199966430664, 97.7200012207031, 97.6600036621094,
              96.8399963378906, 95.6500015258789, 95.2799987792969, 95.2200012207031, 93.6900024414062,
              92.5, 92.0400009155273, 90.4599990844727, 87.4400024414062],
    'Median Nilai Konstruksi yang Diselesaikan (rupiah)': [145000, 80000, 50000, 55000, 70000, 81400, 78000, 75000,
                                                           61000, 50000, 53100, 45000, 90000, 27000, 60000, 54000,
                                                           23000, 35000, 44000, 52000, 30000, 56000, 46000, 42700,
                                                           75000, 67250, 100000, 35000, 90000, 48000, 30000, 70000,
                                                           54250, 71000],
}

# Convert data to a pandas DataFrame
df = pd.DataFrame(data1)

# Mengambil kolom fitur untuk analisis
features = ['Value', 'Median Nilai Konstruksi yang Diselesaikan (rupiah)']

# Convert DataFrame ke array 2D
X = df[features].values

# Normalisasi data numerik
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Terapkan K-Means Clustering untuk mengelompokkan menjadi 3 kategori
kmeans = KMeans(n_clusters=3, random_state=42)
df['Cluster'] = kmeans.fit_predict(X_scaled)

# Menambahkan kategori berdasarkan hasil kluster
df['Category'] = df['Cluster'].map({0: 'Tinggi', 1: 'Rendah'})

# Menampilkan hasil dengan kategori
print(df[['Provinsi', 'Value', 'Median Nilai Konstruksi yang Diselesaikan (rupiah)']])

# Visualisasi Hasil Clustering
plt.figure(figsize=(12, 8))
sns.scatterplot(x=df['Value'], y=df['Median Nilai Konstruksi yang Diselesaikan (rupiah)'], hue=df['Category'], palette='Set1', s=100, alpha=0.8)

# Menambahkan label provinsi ke grafik
for i in range(df.shape[0]):
    plt.text(df['Value'][i] + 0.05, df['Median Nilai Konstruksi yang Diselesaikan (rupiah)'][i], df['Provinsi'][i], fontsize=9, alpha=0.7)

plt.title('Cluster of Provinces Based on IKK')
plt.xlabel('Value (%)')
plt.ylabel('Median Nilai Konstruksi yang Diselesaikan (rupiah)')
plt.legend(title='Category')
plt.grid(True)
plt.show()